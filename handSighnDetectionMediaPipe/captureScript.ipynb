{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 20:56:43.184988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 20:56:43.373952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-05-30 20:56:43.373978: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-30 20:56:44.418239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-05-30 20:56:44.418349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/guilherme/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-05-30 20:56:44.418358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_rect(results, image_shape):\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "        x_max = 0\n",
    "        x_min = image_shape[1]\n",
    "        y_max = 0\n",
    "        y_min = image_shape[0]\n",
    "\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            x = min(image_shape[1], max(0, int(landmark.x * image_shape[1])))\n",
    "            y = min(image_shape[0], max(0, int(landmark.y * image_shape[0])))\n",
    "\n",
    "            x_max = max(x_max, x)\n",
    "            x_min = min(x_min, x)\n",
    "            y_max = max(y_max, y)\n",
    "            y_min = min(y_min, y)\n",
    "\n",
    "        return x_min, y_min, x_max - x_min, y_max - y_min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_hand_image():\n",
    "    folder_path = os.path.abspath('./Data/Fold1/Y')\n",
    "    \n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_hands = mp.solutions.hands\n",
    "    counter = 0\n",
    "\n",
    "    # Inicializa a câmera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Configuração da mediapipe\n",
    "    with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.7\n",
    "    ) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Convertendo o frame para RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detecta as mãos no frame\n",
    "            results = hands.process(image)\n",
    "\n",
    "            # Desenha as landmarks da mão no frame\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image,\n",
    "                        hand_landmarks,\n",
    "                        mp_hands.HAND_CONNECTIONS\n",
    "                    )\n",
    "\n",
    "            # Exibe o frame\n",
    "            cv2.imshow('Hand Detection', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # Captura a imagem quando a tecla 's' for pressionada\n",
    "            if cv2.waitKey(10) & 0xFF == ord('s'):\n",
    "                # Encontra os limites do retângulo que envolve a mão\n",
    "                x, y, w, h = get_bounding_rect(results, frame.shape[:2])\n",
    "\n",
    "                # Recorta a região da mão na imagem original\n",
    "                hand_image = frame[y-30:y+h+50, x-30:x+w+30]\n",
    "\n",
    "                # Salva a imagem da mão isolada\n",
    "                cv2.imwrite(f\"{folder_path}/{counter}.jpg\", cv2.cvtColor(hand_image, cv2.COLOR_RGB2BGR))\n",
    "                counter += 1\n",
    "\n",
    "            if(counter > 9) : break\n",
    "        # Libera os recursos\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    capture_hand_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
